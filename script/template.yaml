data:
  path: "path/to/data.h5ad"
  external_feature_embeddings:
    # Parquet format: gene_id, embedding (both required).
    gene_text: "data/gene_text.parquet"
    gene_protein: "data/gene_protein.parquet"
  check_scaling: true
  split_column: "split"   # obs column name (default: "split")
  train_split_key: "train"
  val_split_key: "val"
  test_split_key: "test"  # or null for no test split
  # Covariates (optional; default null). Encoding saved in checkpoint.
  categorical_covariate_keys: null   # or ['assay_type', 'sex'] for one-hot encoding
  continuous_covariate_keys: null   # or ['age'] for z-score encoding

model:
  hidden_dims: [900, 400]
  latent_dim: 50
  dropout_rate: 0.1
  batchnorm: false
  layernorm: true
  activation: "LeakyReLU"
  fusion_method: "average" # 'average', 'MoE', 'PoE'
  var_eps: 0.0001

training:
  seed: 42
  mode: "direct" # 'direct', 'stepwise', 'beta_vae'
  max_epochs: 500
  batch_size: 128
  devices: 1     # or 2, 4, "auto" for multi-GPU
  strategy: "auto"  # "ddp" for multi-GPU (auto picks ddp when devices > 1)
  learning_rate: 0.001
  patience: 25
  weight_decay: 0.0
  beta_start: 0.0
  beta_end: 1.0
  epochs_before_beta_warmup: 25   # epochs with KL weight = beta_start (no KL)
  beta_warmup_rate: 0.05           # per-epoch increase after warmup (until beta_end)
  gamma: 0.05 # weight for joint loss components

output:
  save_dir: "./results"
  save_key: "X_sciLaMA"  # sample embeddings -> adata.obsm[save_key]
  save_feature_embeddings: true  # feature latent -> parquet (when model has feature VAE)
  feature_embedding_filename: "feature_sciLaMA.parquet"  # gene_id, embedding columns (same format as input)
  save_model: true
